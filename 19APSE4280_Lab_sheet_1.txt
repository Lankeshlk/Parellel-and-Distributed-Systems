hello-world               latest    d211f485f2dd   18 months ago   24.4kB
bde2020/hadoop-namenode   latest    fdf741108051   4 years ago     2.05GB
PS C:\Users\lanke> docker run -it --name hadoop-cluster -p 9870:9870 -p 8088:8088 -p 50070:50070 bde202/hadoop-namenode:latest /bin/bash        
Unable to find image 'bde202/hadoop-namenode:latest' locally
docker: Error response from daemon: pull access denied for bde202/hadoop-namenode, repository does not exist or may require 'docker login'.     
See 'docker run --help'.
PS C:\Users\lanke> docker run -it --name hadoop-cluster -p 9870:9870 -p 8088:8088 -p 50070:50070 bde2020/hadoop-namenode:latest /bin/bash       
docker: Error response from daemon: Conflict. The container name "/hadoop-cluster" is already in use by container "330e79b30a946d51f8666039480cf6460a2a93a6b9f292eabb577b81722ed11d". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
PS C:\Users\lanke>docker run -it --name hadoop-cluster -p 9870:9870 -p 8088:8088 -p 50070:50070 bde2020/hadoop-namenode:latest /bin/bash
docker: Error response from daemon: Conflict. The container name "/hadoop-cluster" is already in use by container "330e79b30a946d51f8666039480cf6460a2a93a6b9f292eabb577b81722ed11d". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
PS C:\Users\lanke> docker rename hadoop-cluster hadoop-cluster-old
PS C:\Users\lanke> docker run -it --name hadoop-cluster -p 9870:9870 -p 8088:8088 -p 50070:50070 bde2020/hadoop-namenode:latest /bin/bash
Configuring core
 - Setting fs.defaultFS=hdfs://4df3c0c3d6e6:8020
Configuring hdfs
 - Setting dfs.namenode.name.dir=file:///hadoop/dfs/name
Configuring yarn
Configuring httpfs
Configuring kms
Configuring mapred
Configuring for multihomed network
root@4df3c0c3d6e6:/# /opt/hadoop-3.2.1/bin/hdfs --daemon start namenode
root@4df3c0c3d6e6:/# /opt/hadoop-3.2.1/bin/hdfs --daemon start datanode
root@4df3c0c3d6e6:/# /opt/hadoop-3.2.1/bin/yarn --daemon start resourcemanager
root@4df3c0c3d6e6:/# /opt/hadoop-3.2.1/bin/yarn --daemon start nodemanager
root@4df3c0c3d6e6:/# hdfs dfs -mkdir -p /user/hadoop/input
mkdir: Call From 4df3c0c3d6e6/172.17.0.2 to 4df3c0c3d6e6:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
root@4df3c0c3d6e6:/# docker exec -it hadoop-cluster /bin/bash
bash: docker: command not found
root@4df3c0c3d6e6:/# hdfs dfs -mkdir -p /user/hadoop/input
mkdir: Call From 4df3c0c3d6e6/172.17.0.2 to 4df3c0c3d6e6:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
root@4df3c0c3d6e6:/# ^C
root@4df3c0c3d6e6:/#jps
624 NodeManager
228 DataNode
344 ResourceManager
1097 Jps
root@4df3c0c3d6e6:/# start-dfs.sh
bash: start-dfs.sh: command not found
root@4df3c0c3d6e6:/#jps
624 NodeManager
228 DataNode
344 ResourceManager
1147 Jps
root@4df3c0c3d6e6:/#hdfs nameode -format
ERROR: nameode is not COMMAND nor fully qualified CLASSNAME.
Usage: hdfs [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]

  OPTIONS is none or any of:

--buildpaths                       attempt to add class files from build tree
--config dir                       Hadoop config directory
--daemon (start|status|stop)       operate on a daemon
--debug                            turn on shell script debug mode
--help                             usage information
--hostnames list[,of,host,names]   hosts to use in worker mode
--hosts filename                   list of hosts to use in worker mode
--loglevel level                   set the log4j level for this command
--workers                          turn on worker mode

  SUBCOMMAND is one of:


    Admin Commands:

cacheadmin           configure the HDFS cache
crypto               configure HDFS encryption zones
debug                run a Debug Admin to execute HDFS debug commands
dfsadmin             run a DFS admin client
dfsrouteradmin       manage Router-based federation
ec                   run a HDFS ErasureCoding CLI
fsck                 run a DFS filesystem checking utility
haadmin              run a DFS HA admin client
jmxget               get JMX exported values from NameNode or DataNode.
oev                  apply the offline edits viewer to an edits file
oiv                  apply the offline fsimage viewer to an fsimage
oiv_legacy           apply the offline fsimage viewer to a legacy fsimage
storagepolicies      list/get/set/satisfyStoragePolicy block storage policies

    Client Commands:

classpath            prints the class path needed to get the hadoop jar and the required libraries
dfs                  run a filesystem command on the file system
envvars              display computed Hadoop environment variables
fetchdt              fetch a delegation token from the NameNode
getconf              get config values from configuration
groups               get the groups which users belong to
lsSnapshottableDir   list all snapshottable dirs owned by the current user
snapshotDiff         diff two snapshots of a directory or diff the current directory contents with a snapshot
version              print the version

    Daemon Commands:

balancer             run a cluster balancing utility
datanode             run a DFS datanode
dfsrouter            run the DFS router
diskbalancer         Distributes data evenly among disks on a given node
httpfs               run HttpFS server, the HDFS HTTP Gateway
journalnode          run the DFS journalnode
mover                run a utility to move block replicas across storage types
namenode             run the DFS namenode
nfs3                 run an NFS version 3 gateway
portmap              run a portmap service
secondarynamenode    run the DFS secondary namenode
sps                  run external storagepolicysatisfier
zkfc                 run the ZK Failover Controller daemon

SUBCOMMAND may print help when invoked w/o parameters or with -h.
root@4df3c0c3d6e6:/#hdfs namenode -format
2024-11-18 08:38:49,467 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = 4df3c0c3d6e6/172.17.0.2
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 1.8.0_232
************************************************************/
2024-11-18 08:38:49,479 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-11-18 08:38:49,535 INFO namenode.NameNode: createNameNode [-format]
Formatting using clusterid: CID-37248689-359e-4cca-86a7-af9eb9b4ee13
2024-11-18 08:38:49,771 INFO namenode.FSEditLog: Edit logging is async:true
2024-11-18 08:38:49,784 INFO namenode.FSNamesystem: KeyProvider: null
2024-11-18 08:38:49,786 INFO namenode.FSNamesystem: fsLock is fair: true
2024-11-18 08:38:49,786 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2024-11-18 08:38:49,789 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2024-11-18 08:38:49,790 INFO namenode.FSNamesystem: supergroup          = supergroup
2024-11-18 08:38:49,790 INFO namenode.FSNamesystem: isPermissionEnabled = true
2024-11-18 08:38:49,790 INFO namenode.FSNamesystem: HA Enabled: false
2024-11-18 08:38:49,821 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2024-11-18 08:38:49,830 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2024-11-18 08:38:49,830 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2024-11-18 08:38:49,832 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2024-11-18 08:38:49,832 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Nov 18 08:38:49
2024-11-18 08:38:49,834 INFO util.GSet: Computing capacity for map BlocksMap
2024-11-18 08:38:49,834 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:38:49,835 INFO util.GSet: 2.0% max memory 1.7 GB = 34.5 MB
2024-11-18 08:38:49,835 INFO util.GSet: capacity      = 2^22 = 4194304 entries
2024-11-18 08:38:49,842 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
2024-11-18 08:38:49,842 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
2024-11-18 08:38:49,847 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2024-11-18 08:38:49,847 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2024-11-18 08:38:49,847 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2024-11-18 08:38:49,847 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: defaultReplication         = 3
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: maxReplication             = 512
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: minReplication             = 1
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
2024-11-18 08:38:49,848 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2024-11-18 08:38:49,886 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2024-11-18 08:38:49,887 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2024-11-18 08:38:49,887 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2024-11-18 08:38:49,887 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2024-11-18 08:38:49,893 INFO util.GSet: Computing capacity for map INodeMap
2024-11-18 08:38:49,893 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:38:49,894 INFO util.GSet: 1.0% max memory 1.7 GB = 17.2 MB
2024-11-18 08:38:49,894 INFO util.GSet: capacity      = 2^21 = 2097152 entries
2024-11-18 08:38:49,895 INFO namenode.FSDirectory: ACLs enabled? false
2024-11-18 08:38:49,895 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
2024-11-18 08:38:49,902 INFO util.GSet: Computing capacity for map cachedBlocks
2024-11-18 08:38:49,902 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:38:49,903 INFO util.GSet: 0.25% max memory 1.7 GB = 4.3 MB---------------------------------------------------------------------------------------------------XX2024-11-18 08:38:49,903 INFO util.GSet: capacity      = 2^19 = 524288 entries
2024-11-18 08:38:49,908 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2024-11-18 08:38:49,909 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2024-11-18 08:38:49,909 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2024-11-18 08:38:49,911 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
2024-11-18 08:38:49,911 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2024-11-18 08:38:49,912 INFO util.GSet: Computing capacity for map NameNodeRetryCache
2024-11-18 08:38:49,912 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:38:49,912 INFO util.GSet: 0.029999999329447746% max memory 1.7 GB = 529.3 KB
2024-11-18 08:38:49,912 INFO util.GSet: capacity      = 2^16 = 65536 entries
2024-11-18 08:38:49,933 INFO namenode.FSImage: Allocated new BlockPoolId: BP-339321231-172.17.0.2-1731919129928
2024-11-18 08:38:49,942 INFO common.Storage: Storage directory /hadoop/dfs/name has been successfully formatted.
2024-11-18 08:38:49,962 INFO namenode.FSImageFormatProtobuf: Saving image file /hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression
2024-11-18 08:38:50,012 INFO namenode.FSImageFormatProtobuf: Image file /hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .  2024-11-18 08:38:50,018 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0-------------------------------------------------------------------XX2024-11-18 08:38:50,022 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.
2024-11-18 08:38:50,022 INFO namenode.NameNode: SHUTDOWN_MSG:--------------------------------------------------------------------------------------------------------------XX/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at 4df3c0c3d6e6/172.17.0.2------------------------------------------------------------------------------------------------------------XX************************************************************/
root@4df3c0c3d6e6:/#hdfs namenode &
[1] 1743
root@4df3c0c3d6e6:/# 2024-11-18 08:52:40,816 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = 4df3c0c3d6e6/172.17.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z      
STARTUP_MSG:   java = 1.8.0_232
************************************************************/
2024-11-18 08:52:40,823 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-11-18 08:52:40,867 INFO namenode.NameNode: createNameNode []
2024-11-18 08:52:40,934 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-11-18 08:52:40,991 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-11-18 08:52:40,991 INFO impl.MetricsSystemImpl: NameNode metrics system started
2024-11-18 08:52:41,006 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://4df3c0c3d6e6:8020
2024-11-18 08:52:41,007 INFO namenode.NameNode: Clients should use 4df3c0c3d6e6:8020 to access this namenode/service.
2024-11-18 08:52:41,070 INFO util.JvmPauseMonitor: Starting JVM pause monitor
2024-11-18 08:52:41,088 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2024-11-18 08:52:41,097 INFO util.log: Logging initialized @520ms
2024-11-18 08:52:41,146 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-11-18 08:52:41,152 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2024-11-18 08:52:41,156 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-11-18 08:52:41,158 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs    
2024-11-18 08:52:41,158 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs    
2024-11-18 08:52:41,158 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static  
2024-11-18 08:52:41,169 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2024-11-18 08:52:41,169 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2024-11-18 08:52:41,174 INFO http.HttpServer2: Jetty bound to port 9870
2024-11-18 08:52:41,175 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2024-11-18 08:52:41,192 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d0b7e3c{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}
2024-11-18 08:52:41,192 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b741d6d{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2024-11-18 08:52:41,242 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7486b455{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2024-11-18 08:52:41,246 INFO server.AbstractConnector: Started ServerConnector@700fb871{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}
2024-11-18 08:52:41,246 INFO server.Server: Started @669ms
2024-11-18 08:52:41,327 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2024-11-18 08:52:41,328 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2024-11-18 08:52:41,368 INFO namenode.FSEditLog: Edit logging is async:true
2024-11-18 08:52:41,394 INFO namenode.FSNamesystem: KeyProvider: null
2024-11-18 08:52:41,394 INFO namenode.FSNamesystem: fsLock is fair: true
2024-11-18 08:52:41,394 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2024-11-18 08:52:41,397 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2024-11-18 08:52:41,397 INFO namenode.FSNamesystem: supergroup          = supergroup
2024-11-18 08:52:41,397 INFO namenode.FSNamesystem: isPermissionEnabled = true
2024-11-18 08:52:41,397 INFO namenode.FSNamesystem: HA Enabled: false
2024-11-18 08:52:41,415 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2024-11-18 08:52:41,419 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2024-11-18 08:52:41,419 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2024-11-18 08:52:41,421 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2024-11-18 08:52:41,421 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Nov 18 08:52:41
2024-11-18 08:52:41,423 INFO util.GSet: Computing capacity for map BlocksMap
2024-11-18 08:52:41,423 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:52:41,423 INFO util.GSet: 2.0% max memory 1.7 GB = 34.5 MB
2024-11-18 08:52:41,423 INFO util.GSet: capacity      = 2^22 = 4194304 entries
2024-11-18 08:52:41,429 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
2024-11-18 08:52:41,429 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
2024-11-18 08:52:41,432 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2024-11-18 08:52:41,432 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: defaultReplication         = 3
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: maxReplication             = 512
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: minReplication             = 1
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
2024-11-18 08:52:41,433 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2024-11-18 08:52:41,447 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2024-11-18 08:52:41,447 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2024-11-18 08:52:41,447 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2024-11-18 08:52:41,447 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2024-11-18 08:52:41,454 INFO util.GSet: Computing capacity for map INodeMap
2024-11-18 08:52:41,454 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:52:41,454 INFO util.GSet: 1.0% max memory 1.7 GB = 17.2 MB
2024-11-18 08:52:41,454 INFO util.GSet: capacity      = 2^21 = 2097152 entries
2024-11-18 08:52:41,456 INFO namenode.FSDirectory: ACLs enabled? false
2024-11-18 08:52:41,456 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
2024-11-18 08:52:41,456 INFO namenode.FSDirectory: XAttrs enabled? true
2024-11-18 08:52:41,456 INFO namenode.NameNode: Caching file names occurring more than 10 times
2024-11-18 08:52:41,459 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2024-11-18 08:52:41,460 INFO snapshot.SnapshotManager: SkipList is disabled
2024-11-18 08:52:41,463 INFO util.GSet: Computing capacity for map cachedBlocks
2024-11-18 08:52:41,463 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:52:41,464 INFO util.GSet: 0.25% max memory 1.7 GB = 4.3 MB
2024-11-18 08:52:41,464 INFO util.GSet: capacity      = 2^19 = 524288 entries
2024-11-18 08:52:41,468 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2024-11-18 08:52:41,468 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2024-11-18 08:52:41,468 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2024-11-18 08:52:41,470 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
2024-11-18 08:52:41,470 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2024-11-18 08:52:41,471 INFO util.GSet: Computing capacity for map NameNodeRetryCache
2024-11-18 08:52:41,471 INFO util.GSet: VM type       = 64-bit
2024-11-18 08:52:41,471 INFO util.GSet: 0.029999999329447746% max memory 1.7 GB = 529.3 KB
2024-11-18 08:52:41,471 INFO util.GSet: capacity      = 2^16 = 65536 entries
2024-11-18 08:52:41,483 INFO common.Storage: Lock on /hadoop/dfs/name/in_use.lock acquired by nodename 1743@4df3c0c3d6e6
2024-11-18 08:52:41,496 INFO namenode.FileJournalManager: Recovering unfinalized segments in /hadoop/dfs/name/current
2024-11-18 08:52:41,497 INFO namenode.FSImage: No edit log streams selected.
2024-11-18 08:52:41,497 INFO namenode.FSImage: Planning to load image: FSImageFile(file=/hadoop/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2024-11-18 08:52:41,531 INFO namenode.FSImageFormatPBINode: Loading 1 INodes.
2024-11-18 08:52:41,546 INFO namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2024-11-18 08:52:41,546 INFO namenode.FSImage: Loaded image for txid 0 from /hadoop/dfs/name/current/fsimage_0000000000000000000
2024-11-18 08:52:41,549 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2024-11-18 08:52:41,550 INFO namenode.FSEditLog: Starting log segment at 1
2024-11-18 08:52:41,612 INFO namenode.NameCache: initialized with 0 entries 0 lookups
2024-11-18 08:52:41,613 INFO namenode.FSNamesystem: Finished loading FSImage in 140 msecs
2024-11-18 08:52:41,773 INFO namenode.NameNode: RPC server is binding to 0.0.0.0:8020
2024-11-18 08:52:41,787 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-11-18 08:52:41,792 INFO ipc.Server: Starting Socket Reader #1 for port 8020
2024-11-18 08:52:41,900 INFO namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2024-11-18 08:52:41,907 INFO namenode.LeaseManager: Number of blocks under construction: 0
2024-11-18 08:52:41,914 INFO blockmanagement.BlockManager: initializing replication queues
2024-11-18 08:52:41,914 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2024-11-18 08:52:41,914 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2024-11-18 08:52:41,914 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2024-11-18 08:52:41,920 INFO blockmanagement.BlockManager: Total number of blocks            = 0
2024-11-18 08:52:41,920 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
2024-11-18 08:52:41,920 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
2024-11-18 08:52:41,920 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2024-11-18 08:52:41,920 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
2024-11-18 08:52:41,920 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2024-11-18 08:52:41,928 INFO ipc.Server: IPC Server Responder: starting
2024-11-18 08:52:41,928 INFO ipc.Server: IPC Server listener on 8020: starting
2024-11-18 08:52:41,931 INFO namenode.NameNode: NameNode RPC up at: 4df3c0c3d6e6/172.17.0.2:8020
2024-11-18 08:52:41,933 INFO namenode.FSNamesystem: Starting services required for active state
2024-11-18 08:52:41,933 INFO namenode.FSDirectory: Initializing quota with 4 thread(s)
2024-11-18 08:52:41,937 INFO namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2024-11-18 08:52:41,940 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2024-11-18 08:52:42,432 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.17.0.2:9866, datanodeUuid=e25528c7-5cd1-458d-8c69-97ea5bdce301, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-37248689-359e-4cca-86a7-af9eb9b4ee13;nsid=528561600;c=1731919129928) storage e25528c7-5cd1-458d-8c69-97ea5bdce301
2024-11-18 08:52:42,433 INFO net.NetworkTopology: Adding a new node: /default-rack/172.17.0.2:9866
2024-11-18 08:52:42,433 INFO blockmanagement.BlockReportLeaseManager: Registered DN e25528c7-5cd1-458d-8c69-97ea5bdce301 (172.17.0.2:9866).
2024-11-18 08:52:42,474 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2a193ac8-a206-489c-8b61-354e2f1f7622 for DN 172.17.0.2:9866
2024-11-18 08:52:42,498 INFO BlockStateChange: BLOCK* processReport 0x350c1a9a03d3eee7: Processing first storage report for DS-2a193ac8-a206-489c-8b61-354e2f1f7622 from datanode e25528c7-5cd1-458d-8c69-97ea5bdce301
2024-11-18 08:52:42,499 INFO BlockStateChange: BLOCK* processReport 0x350c1a9a03d3eee7: from storage DS-2a193ac8-a206-489c-8b61-354e2f1f7622 node DatanodeRegistration(172.17.0.2:9866, datanodeUuid=e25528c7-5cd1-458d-8c69-97ea5bdce301, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-37248689-359e-4cca-86a7-af9eb9b4ee13;nsid=528561600;c=1731919129928), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0

root@4df3c0c3d6e6:/#hdfs datanode &
[2] 1943
root@4df3c0c3d6e6:/#2024-11-18 08:56:49,540 INFO datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = 4df3c0c3d6e6/172.17.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z      
STARTUP_MSG:   java = 1.8.0_232
************************************************************/
2024-11-18 08:56:49,552 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-11-18 08:56:49,785 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data
2024-11-18 08:56:49,847 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-11-18 08:56:49,897 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-11-18 08:56:49,897 INFO impl.MetricsSystemImpl: DataNode metrics system started
2024-11-18 08:56:49,999 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2024-11-18 08:56:50,001 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-11-18 08:56:50,005 INFO datanode.DataNode: Configured hostname is 4df3c0c3d6e6
2024-11-18 08:56:50,005 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2024-11-18 08:56:50,009 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-11-18 08:56:50,029 INFO datanode.DataNode: Shutdown complete.
2024-11-18 08:56:50,030 ERROR datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:9866] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:738)
        at org.apache.hadoop.ipc.Server.bind(Server.java:620)
        at org.apache.hadoop.ipc.Server.bind(Server.java:592)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:52)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1141)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1417)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:501)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2806)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2714)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2756)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2900)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2924)
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.apache.hadoop.ipc.Server.bind(Server.java:603)
        ... 10 more
2024-11-18 08:56:50,032 INFO util.ExitUtil: Exiting with status 1: java.net.BindException: Problem binding to [0.0.0.0:9866] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
2024-11-18 08:56:50,034 INFO datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at 4df3c0c3d6e6/172.17.0.2
************************************************************/

[2]+  Exit 1                  hdfs datanode
root@4df3c0c3d6e6:/#yarn nodemanager &
[2] 2032
root@4df3c0c3d6e6:/#2024-11-18 08:57:25,460 INFO nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = 4df3c0c3d6e6/172.17.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-client-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-common-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z      
STARTUP_MSG:   java = 1.8.0_232
************************************************************/
2024-11-18 08:57:25,466 INFO nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2024-11-18 08:57:25,645 INFO resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2024-11-18 08:57:25,645 INFO resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2024-11-18 08:57:25,686 INFO nodemanager.NodeManager: Node Manager health check script is not available or doesn't have execute permission, so not starting the node health script runner.
2024-11-18 08:57:25,726 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2024-11-18 08:57:25,726 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2024-11-18 08:57:25,727 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2024-11-18 08:57:25,728 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2024-11-18 08:57:25,728 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2024-11-18 08:57:25,728 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2024-11-18 08:57:25,729 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2024-11-18 08:57:25,730 INFO tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2024-11-18 08:57:25,745 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2024-11-18 08:57:25,745 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2024-11-18 08:57:25,773 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-11-18 08:57:25,806 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-11-18 08:57:25,807 INFO impl.MetricsSystemImpl: NodeManager metrics system started
2024-11-18 08:57:25,820 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2024-11-18 08:57:25,826 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2024-11-18 08:57:25,845 INFO nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@2e6a8155
2024-11-18 08:57:25,846 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2024-11-18 08:57:25,847 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2024-11-18 08:57:25,847 INFO containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2024-11-18 08:57:25,847 INFO localizer.ResourceLocalizationService: per directory file limit = 8192
2024-11-18 08:57:25,880 INFO localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-root/nm-local-dir/usercache_DEL_1731920245850
2024-11-18 08:57:25,894 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2024-11-18 08:57:25,898 INFO resources.ResourceHandlerModule: Using traffic control bandwidth handler
2024-11-18 08:57:25,899 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@53fb3dab
2024-11-18 08:57:25,900 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2024-11-18 08:57:25,900 INFO monitor.ContainersMonitorImpl: Physical memory check enabled: true
2024-11-18 08:57:25,900 INFO monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2024-11-18 08:57:25,900 INFO monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2024-11-18 08:57:25,900 INFO monitor.ContainersMonitorImpl: Strict memory control enabled: true
2024-11-18 08:57:25,900 INFO monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2024-11-18 08:57:25,902 WARN monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (7.6 G). Thrashing might happen.
2024-11-18 08:57:25,902 INFO containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2024-11-18 08:57:25,915 INFO conf.Configuration: resource-types.xml not found
2024-11-18 08:57:25,915 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-11-18 08:57:25,919 INFO conf.Configuration: node-resources.xml not found
2024-11-18 08:57:25,919 INFO resource.ResourceUtils: Unable to find 'node-resources.xml'.
2024-11-18 08:57:25,921 INFO nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2024-11-18 08:57:25,924 INFO nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2024-11-18 08:57:25,972 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-11-18 08:57:25,982 INFO ipc.Server: Starting Socket Reader #1 for port 0
2024-11-18 08:57:26,088 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2024-11-18 08:57:26,088 INFO ipc.Server: IPC Server Responder: starting
2024-11-18 08:57:26,089 INFO ipc.Server: IPC Server listener on 0: starting
2024-11-18 08:57:26,096 INFO security.NMContainerTokenSecretManager: Updating node address : 4df3c0c3d6e6:45351
2024-11-18 08:57:26,101 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-11-18 08:57:26,103 INFO service.AbstractService: Service org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService failed in state STARTED
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:138)
        at org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC.getServer(HadoopYarnProtoRPC.java:65)
        at org.apache.hadoop.yarn.ipc.YarnRPC.getServer(YarnRPC.java:54)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.createServer(ResourceLocalizationService.java:409)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.serviceStart(ResourceLocalizationService.java:385)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceStart(ContainerManagerImpl.java:668)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:975)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:1054)
Caused by: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:738)
        at org.apache.hadoop.ipc.Server.bind(Server.java:620)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1184)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:3066)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1039)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:426)
        at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:347)
        at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:848)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.createServer(RpcServerFactoryPBImpl.java:172)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:131)
        ... 12 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.apache.hadoop.ipc.Server.bind(Server.java:603)
        ... 20 more
2024-11-18 08:57:26,105 INFO service.AbstractService: Service org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl failed in state STARTED     
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:138)
        at org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC.getServer(HadoopYarnProtoRPC.java:65)
        at org.apache.hadoop.yarn.ipc.YarnRPC.getServer(YarnRPC.java:54)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.createServer(ResourceLocalizationService.java:409)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.serviceStart(ResourceLocalizationService.java:385)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceStart(ContainerManagerImpl.java:668)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:975)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:1054)
Caused by: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:738)
        at org.apache.hadoop.ipc.Server.bind(Server.java:620)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1184)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:3066)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1039)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:426)
        at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:347)
        at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:848)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.createServer(RpcServerFactoryPBImpl.java:172)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:131)
        ... 12 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.apache.hadoop.ipc.Server.bind(Server.java:603)
        ... 20 more
2024-11-18 08:57:26,105 INFO ipc.Server: Stopping server on 45351
2024-11-18 08:57:26,106 INFO ipc.Server: Stopping IPC Server listener on 0
2024-11-18 08:57:26,107 INFO ipc.Server: Stopping IPC Server Responder
2024-11-18 08:57:26,107 INFO service.AbstractService: Service NodeManager failed in state STARTED
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:138)
        at org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC.getServer(HadoopYarnProtoRPC.java:65)
        at org.apache.hadoop.yarn.ipc.YarnRPC.getServer(YarnRPC.java:54)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.createServer(ResourceLocalizationService.java:409)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.serviceStart(ResourceLocalizationService.java:385)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceStart(ContainerManagerImpl.java:668)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:975)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:1054)
Caused by: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:738)
        at org.apache.hadoop.ipc.Server.bind(Server.java:620)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1184)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:3066)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1039)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:426)
        at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:347)
        at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:848)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.createServer(RpcServerFactoryPBImpl.java:172)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:131)
        ... 12 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.apache.hadoop.ipc.Server.bind(Server.java:603)
        ... 20 more
2024-11-18 08:57:26,107 WARN nodemanager.NodeResourceMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl is interrupted. Exiting.
2024-11-18 08:57:26,108 INFO impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2024-11-18 08:57:26,108 INFO impl.MetricsSystemImpl: NodeManager metrics system stopped.
2024-11-18 08:57:26,108 INFO impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2024-11-18 08:57:26,108 ERROR nodemanager.NodeManager: Error starting NodeManager
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:138)
        at org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC.getServer(HadoopYarnProtoRPC.java:65)
        at org.apache.hadoop.yarn.ipc.YarnRPC.getServer(YarnRPC.java:54)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.createServer(ResourceLocalizationService.java:409)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.serviceStart(ResourceLocalizationService.java:385)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceStart(ContainerManagerImpl.java:668)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:975)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:1054)
Caused by: java.net.BindException: Problem binding to [0.0.0.0:8040] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:738)
        at org.apache.hadoop.ipc.Server.bind(Server.java:620)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1184)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:3066)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1039)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:426)
        at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:347)
        at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:848)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.createServer(RpcServerFactoryPBImpl.java:172)
        at org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(RpcServerFactoryPBImpl.java:131)
        ... 12 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.apache.hadoop.ipc.Server.bind(Server.java:603)
        ... 20 more
2024-11-18 08:57:26,110 INFO nodemanager.NodeManager: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at 4df3c0c3d6e6/172.17.0.2
************************************************************/

[2]+  Exit 255                yarn nodemanager
root@4df3c0c3d6e6:/#yarn resourcemanager &
[2] 2181
root@4df3c0c3d6e6:/#2024-11-18 08:57:41,709 INFO resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = 4df3c0c3d6e6/172.17.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-client-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-common-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z      
STARTUP_MSG:   java = 1.8.0_232
************************************************************/
2024-11-18 08:57:41,718 INFO resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2024-11-18 08:57:41,854 INFO conf.Configuration: found resource core-site.xml at file:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
2024-11-18 08:57:41,875 INFO conf.Configuration: resource-types.xml not found
2024-11-18 08:57:41,875 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-11-18 08:57:41,910 INFO conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-3.2.1/etc/hadoop/yarn-site.xml
2024-11-18 08:57:41,919 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2024-11-18 08:57:41,939 INFO security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2024-11-18 08:57:41,942 INFO security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2024-11-18 08:57:41,946 INFO security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2024-11-18 08:57:41,971 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2024-11-18 08:57:41,974 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2024-11-18 08:57:41,974 INFO resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2024-11-18 08:57:41,997 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher
2024-11-18 08:57:41,998 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2024-11-18 08:57:41,998 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2024-11-18 08:57:41,999 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2024-11-18 08:57:42,033 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-11-18 08:57:42,063 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-11-18 08:57:42,063 INFO impl.MetricsSystemImpl: ResourceManager metrics system started
2024-11-18 08:57:42,072 INFO security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2024-11-18 08:57:42,076 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2024-11-18 08:57:42,081 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2024-11-18 08:57:42,082 INFO resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2024-11-18 08:57:42,082 INFO monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.
2024-11-18 08:57:42,085 INFO placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager
2024-11-18 08:57:42,086 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list
2024-11-18 08:57:42,090 INFO conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-3.2.1/etc/hadoop/capacity-scheduler.xml
2024-11-18 08:57:42,099 INFO scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1024, vCores:1>
2024-11-18 08:57:42,099 INFO scheduler.AbstractYarnScheduler: Maximum allocation = <memory:8192, vCores:4>
2024-11-18 08:57:42,126 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2024-11-18 08:57:42,126 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2024-11-18 08:57:42,131 INFO capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true, orderingPolicy=utilization, priority=0
2024-11-18 08:57:42,131 INFO capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2024-11-18 08:57:42,138 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2024-11-18 08:57:42,138 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2024-11-18 08:57:42,140 INFO capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
absoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
effectiveMinResource=<memory:0, vCores:0>
 , effectiveMaxResource=<memory:0, vCores:0>
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
rackLocalityAdditionalDelay = -1
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
priority = 0
maxLifetime = -1 seconds
defaultLifetime = -1 seconds
2024-11-18 08:57:42,140 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0, effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0>
2024-11-18 08:57:42,140 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2024-11-18 08:57:42,141 INFO capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2024-11-18 08:57:42,142 INFO placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false
2024-11-18 08:57:42,142 INFO placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are
2024-11-18 08:57:42,142 INFO capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false
2024-11-18 08:57:42,145 INFO conf.Configuration: dynamic-resources.xml not found
2024-11-18 08:57:42,146 INFO resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].
2024-11-18 08:57:42,146 INFO resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.
2024-11-18 08:57:42,147 INFO resourcemanager.AMSProcessingChain: Adding [org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor] tp top of AMS Processing chain.
2024-11-18 08:57:42,152 INFO resourcemanager.ResourceManager: TimelineServicePublisher is not configured
2024-11-18 08:57:42,179 INFO util.log: Logging initialized @703ms
2024-11-18 08:57:42,226 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-11-18 08:57:42,228 INFO http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2024-11-18 08:57:42,232 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-11-18 08:57:42,233 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2024-11-18 08:57:42,233 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2024-11-18 08:57:42,233 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2024-11-18 08:57:42,234 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster 
2024-11-18 08:57:42,234 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs    
2024-11-18 08:57:42,234 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static  
2024-11-18 08:57:42,236 INFO http.HttpServer2: adding path spec: /cluster/*
2024-11-18 08:57:42,236 INFO http.HttpServer2: adding path spec: /ws/*
2024-11-18 08:57:42,236 INFO http.HttpServer2: adding path spec: /app/*
2024-11-18 08:57:42,444 INFO webapp.WebApps: Registered webapp guice modules
2024-11-18 08:57:42,448 INFO http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:8088
        at org.apache.hadoop.http.HttpServer2.constructBindException(HttpServer2.java:1218)
        at org.apache.hadoop.http.HttpServer2.bindForSinglePort(HttpServer2.java:1240)
        at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:1299)
        at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1154)
        at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:439)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp(ResourceManager.java:1231)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1340)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1535)
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:351)
        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:319)
        at org.apache.hadoop.http.HttpServer2.bindListener(HttpServer2.java:1205)
        at org.apache.hadoop.http.HttpServer2.bindForSinglePort(HttpServer2.java:1236)
        ... 7 more
2024-11-18 08:57:42,449 INFO service.AbstractService: Service ResourceManager failed in state STARTED
org.apache.hadoop.yarn.webapp.WebAppException: Error starting http server
        at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:443)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp(ResourceManager.java:1231)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1340)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1535)
Caused by: java.net.BindException: Port in use: 0.0.0.0:8088
        at org.apache.hadoop.http.HttpServer2.constructBindException(HttpServer2.java:1218)
        at org.apache.hadoop.http.HttpServer2.bindForSinglePort(HttpServer2.java:1240)
        at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:1299)
        at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1154)
        at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:439)
        ... 4 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:351)
        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:319)
        at org.apache.hadoop.http.HttpServer2.bindListener(HttpServer2.java:1205)
        at org.apache.hadoop.http.HttpServer2.bindForSinglePort(HttpServer2.java:1236)
        ... 7 more
2024-11-18 08:57:42,450 INFO resourcemanager.ResourceManager: Transitioning to standby state
2024-11-18 08:57:42,450 INFO resourcemanager.ResourceManager: Transitioned to standby state
2024-11-18 08:57:42,450 FATAL resourcemanager.ResourceManager: Error starting ResourceManager
org.apache.hadoop.yarn.webapp.WebAppException: Error starting http server
        at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:443)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp(ResourceManager.java:1231)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1340)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1535)
Caused by: java.net.BindException: Port in use: 0.0.0.0:8088
        at org.apache.hadoop.http.HttpServer2.constructBindException(HttpServer2.java:1218)
        at org.apache.hadoop.http.HttpServer2.bindForSinglePort(HttpServer2.java:1240)
        at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:1299)
        at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1154)
        at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:439)
        ... 4 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:351)
        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:319)
        at org.apache.hadoop.http.HttpServer2.bindListener(HttpServer2.java:1205)
        at org.apache.hadoop.http.HttpServer2.bindForSinglePort(HttpServer2.java:1236)
        ... 7 more
2024-11-18 08:57:42,452 INFO resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at 4df3c0c3d6e6/172.17.0.2
************************************************************/

[2]+  Exit 255                yarn resourcemanager
root@4df3c0c3d6e6:/#hdfs dfs -put $HADOOP_HOME/etc/hadoop/*.xml /user/hadoop/input
put: `/user/hadoop/input': No such file or directory
root@4df3c0c3d6e6:/# hdfs dfs -mkdir -p /user/hadoop/input
2024-11-18 08:58:26,126 INFO namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4
root@4df3c0c3d6e6:/# hdfs dfs -put $HADOOP_HOME/etc/hadoop/*.xml /user/hadoop/input
2024-11-18 08:58:37,667 INFO hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.17.0.2:9866 for /user/hadoop/input/capacity-scheduler.xml._COPYING_
2024-11-18 08:58:37,684 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:37,816 INFO namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/capacity-scheduler.xml._COPYING_
2024-11-18 08:58:38,221 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/capacity-scheduler.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:38,240 INFO hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.17.0.2:9866 for /user/hadoop/input/core-site.xml._COPYING_
2024-11-18 08:58:38,242 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:38,247 INFO namenode.FSNamesystem: BLOCK* blk_1073741826_1002 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/core-site.xml._COPYING_
2024-11-18 08:58:38,652 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/core-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:38,665 INFO hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.17.0.2:9866 for /user/hadoop/input/hadoop-policy.xml._COPYING_
2024-11-18 08:58:38,667 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:38,672 INFO namenode.FSNamesystem: BLOCK* blk_1073741827_1003 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/hadoop-policy.xml._COPYING_
2024-11-18 08:58:39,074 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/hadoop-policy.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:39,086 INFO hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.17.0.2:9866 for /user/hadoop/input/hdfs-site.xml._COPYING_
2024-11-18 08:58:39,088 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:39,092 INFO namenode.FSNamesystem: BLOCK* blk_1073741828_1004 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/hdfs-site.xml._COPYING_
2024-11-18 08:58:39,494 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/hdfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:39,505 INFO hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.17.0.2:9866 for /user/hadoop/input/httpfs-site.xml._COPYING_
2024-11-18 08:58:39,507 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:39,512 INFO namenode.FSNamesystem: BLOCK* blk_1073741829_1005 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/httpfs-site.xml._COPYING_
2024-11-18 08:58:39,914 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/httpfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:39,925 INFO hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.17.0.2:9866 for /user/hadoop/input/kms-acls.xml._COPYING_
2024-11-18 08:58:39,927 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:39,931 INFO namenode.FSNamesystem: BLOCK* blk_1073741830_1006 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/kms-acls.xml._COPYING_
2024-11-18 08:58:40,333 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/kms-acls.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:40,346 INFO hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.17.0.2:9866 for /user/hadoop/input/kms-site.xml._COPYING_
2024-11-18 08:58:40,348 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:40,352 INFO namenode.FSNamesystem: BLOCK* blk_1073741831_1007 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/hadoop/input/kms-site.xml._COPYING_
2024-11-18 08:58:40,754 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/kms-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:40,763 INFO hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.17.0.2:9866 for /user/hadoop/input/mapred-site.xml._COPYING_
2024-11-18 08:58:40,765 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:40,770 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/mapred-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
2024-11-18 08:58:40,778 INFO hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.17.0.2:9866 for /user/hadoop/input/yarn-site.xml._COPYING_
2024-11-18 08:58:40,779 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:58:40,784 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/input/yarn-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_874747804_1
root@4df3c0c3d6e6:/# hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /user/hadoop/input /user/hadoop/output
2024-11-18 08:59:04,195 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-11-18 08:59:04,243 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-11-18 08:59:04,243 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2024-11-18 08:59:04,397 INFO input.FileInputFormat: Total input files to process : 9
2024-11-18 08:59:04,413 INFO mapreduce.JobSubmitter: number of splits:9
2024-11-18 08:59:04,495 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local850210037_0001
2024-11-18 08:59:04,495 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-11-18 08:59:04,564 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2024-11-18 08:59:04,565 INFO mapreduce.Job: Running job: job_local850210037_0001
2024-11-18 08:59:04,565 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2024-11-18 08:59:04,570 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:04,570 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:04,571 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-11-18 08:59:04,600 INFO mapred.LocalJobRunner: Waiting for map tasks
2024-11-18 08:59:04,600 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000000_0
2024-11-18 08:59:04,616 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:04,616 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:04,626 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:04,629 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/hadoop-policy.xml:0+11392
2024-11-18 08:59:04,670 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:04,670 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:04,670 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:04,670 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:04,670 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:04,673 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:04,696 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:59:04,775 INFO mapred.LocalJobRunner: 
2024-11-18 08:59:04,777 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:04,777 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:04,777 INFO mapred.MapTask: bufstart = 0; bufend = 15783; bufvoid = 104857600
2024-11-18 08:59:04,777 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209160(104836640); length = 5237/6553600
2024-11-18 08:59:04,793 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:04,800 INFO mapred.Task: Task:attempt_local850210037_0001_m_000000_0 is done. And is in the process of committing
2024-11-18 08:59:04,803 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:04,803 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000000_0' done.
2024-11-18 08:59:04,808 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=317864
                FILE: Number of bytes written=845822
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=11392
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=5
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=265
                Map output records=1310
                Map output bytes=15783
                Map output materialized bytes=5170
                Input split bytes=125
                Combine input records=1310
                Combine output records=256
                Spilled Records=256
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=287309824
        File Input Format Counters
                Bytes Read=11392
2024-11-18 08:59:04,809 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000000_0
2024-11-18 08:59:04,809 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000001_0
2024-11-18 08:59:04,810 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:04,810 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:04,811 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:04,812 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/capacity-scheduler.xml:0+8260
2024-11-18 08:59:04,854 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:04,854 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:04,854 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:04,854 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:04,854 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:04,856 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:04,863 INFO mapred.LocalJobRunner:
2024-11-18 08:59:04,863 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:04,864 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:04,864 INFO mapred.MapTask: bufstart = 0; bufend = 10690; bufvoid = 104857600
2024-11-18 08:59:04,864 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26211072(104844288); length = 3325/6553600
2024-11-18 08:59:04,867 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:04,868 INFO mapred.Task: Task:attempt_local850210037_0001_m_000001_0 is done. And is in the process of committing
2024-11-18 08:59:04,872 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:04,872 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000001_0' done.
2024-11-18 08:59:04,873 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000001_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=318995
                FILE: Number of bytes written=852187
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=19652
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=7
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=220
                Map output records=832
                Map output bytes=10690
                Map output materialized bytes=6333
                Input split bytes=130
                Combine input records=832
                Combine output records=356
                Spilled Records=356
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=392691712
        File Input Format Counters
                Bytes Read=8260
2024-11-18 08:59:04,873 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000001_0
2024-11-18 08:59:04,873 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000002_0
2024-11-18 08:59:04,875 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:04,875 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:04,875 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:04,876 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/kms-acls.xml:0+3518
2024-11-18 08:59:04,913 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:04,913 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:04,913 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:04,913 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:04,913 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:04,914 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:04,919 INFO mapred.LocalJobRunner:
2024-11-18 08:59:04,920 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:04,920 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:04,920 INFO mapred.MapTask: bufstart = 0; bufend = 4413; bufvoid = 104857600
2024-11-18 08:59:04,920 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213072(104852288); length = 1325/6553600
2024-11-18 08:59:04,921 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:04,922 INFO mapred.Task: Task:attempt_local850210037_0001_m_000002_0 is done. And is in the process of committing
2024-11-18 08:59:04,924 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:04,924 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000002_0' done.
2024-11-18 08:59:04,924 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000002_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=320126
                FILE: Number of bytes written=854599
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=23170
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=135
                Map output records=332
                Map output bytes=4413
                Map output materialized bytes=2380
                Input split bytes=120
                Combine input records=332
                Combine output records=139
                Spilled Records=139
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=498073600
        File Input Format Counters
                Bytes Read=3518
2024-11-18 08:59:04,925 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000002_0
2024-11-18 08:59:04,925 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000003_0
2024-11-18 08:59:04,926 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:04,926 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:04,926 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:04,927 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/hdfs-site.xml:0+1385
2024-11-18 08:59:04,963 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:04,964 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:04,964 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:04,964 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:04,964 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:04,964 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:04,968 INFO mapred.LocalJobRunner:
2024-11-18 08:59:04,968 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:04,968 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:04,968 INFO mapred.MapTask: bufstart = 0; bufend = 1792; bufvoid = 104857600
2024-11-18 08:59:04,968 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213968(104855872); length = 429/6553600
2024-11-18 08:59:04,971 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:04,972 INFO mapred.Task: Task:attempt_local850210037_0001_m_000003_0 is done. And is in the process of committing
2024-11-18 08:59:04,974 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:04,974 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000003_0' done.
2024-11-18 08:59:04,975 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000003_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=321257
                FILE: Number of bytes written=856409
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=24555
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=11
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=28
                Map output records=108
                Map output bytes=1792
                Map output materialized bytes=1778
                Input split bytes=121
                Combine input records=108
                Combine output records=87
                Spilled Records=87
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=603455488
        File Input Format Counters
                Bytes Read=1385
2024-11-18 08:59:04,975 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000003_0
2024-11-18 08:59:04,975 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000004_0
2024-11-18 08:59:04,976 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:04,976 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:04,976 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:04,976 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/yarn-site.xml:0+1031
2024-11-18 08:59:05,012 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:05,012 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:05,012 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:05,012 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:05,012 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:05,013 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:05,016 INFO mapred.LocalJobRunner:
2024-11-18 08:59:05,017 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:05,017 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:05,017 INFO mapred.MapTask: bufstart = 0; bufend = 1403; bufvoid = 104857600
2024-11-18 08:59:05,017 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214004(104856016); length = 393/6553600
2024-11-18 08:59:05,018 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:05,019 INFO mapred.Task: Task:attempt_local850210037_0001_m_000004_0 is done. And is in the process of committing
2024-11-18 08:59:05,020 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:05,020 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000004_0' done.
2024-11-18 08:59:05,021 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000004_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=322388
                FILE: Number of bytes written=857740
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=25586
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=13
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=23
                Map output records=99
                Map output bytes=1403
                Map output materialized bytes=1299
                Input split bytes=121
                Combine input records=99
                Combine output records=79
                Spilled Records=79
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=708837376
        File Input Format Counters
                Bytes Read=1031
2024-11-18 08:59:05,021 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000004_0
2024-11-18 08:59:05,021 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000005_0
2024-11-18 08:59:05,022 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:05,022 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:05,022 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:05,024 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/core-site.xml:0+860
2024-11-18 08:59:05,061 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:05,061 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:05,062 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:05,062 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:05,062 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:05,062 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:05,067 INFO mapred.LocalJobRunner:
2024-11-18 08:59:05,067 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:05,067 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:05,067 INFO mapred.MapTask: bufstart = 0; bufend = 1244; bufvoid = 104857600
2024-11-18 08:59:05,067 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213992(104855968); length = 405/6553600
2024-11-18 08:59:05,068 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:05,069 INFO mapred.Task: Task:attempt_local850210037_0001_m_000005_0 is done. And is in the process of committing
2024-11-18 08:59:05,071 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:05,071 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000005_0' done.
2024-11-18 08:59:05,071 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000005_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=323007
                FILE: Number of bytes written=858990
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=26446
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=15
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=21
                Map output records=102
                Map output bytes=1244
                Map output materialized bytes=1218
                Input split bytes=121
                Combine input records=102
                Combine output records=81
                Spilled Records=81
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=814219264
        File Input Format Counters
                Bytes Read=860
2024-11-18 08:59:05,072 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000005_0
2024-11-18 08:59:05,072 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000006_0
2024-11-18 08:59:05,072 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:05,072 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:05,073 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:05,074 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/mapred-site.xml:0+841
2024-11-18 08:59:05,109 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:05,109 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:05,109 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:05,109 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:05,110 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:05,111 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:05,115 INFO mapred.LocalJobRunner:
2024-11-18 08:59:05,115 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:05,115 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:05,115 INFO mapred.MapTask: bufstart = 0; bufend = 1220; bufvoid = 104857600
2024-11-18 08:59:05,115 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
2024-11-18 08:59:05,116 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:05,117 INFO mapred.Task: Task:attempt_local850210037_0001_m_000006_0 is done. And is in the process of committing
2024-11-18 08:59:05,119 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:05,119 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000006_0' done.
2024-11-18 08:59:05,119 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000006_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=323626
                FILE: Number of bytes written=860214
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=27287
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=17
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=22
                Map output records=101
                Map output bytes=1220
                Map output materialized bytes=1192
                Input split bytes=123
                Combine input records=101
                Combine output records=80
                Spilled Records=80
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=919601152
        File Input Format Counters
                Bytes Read=841
2024-11-18 08:59:05,119 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000006_0
2024-11-18 08:59:05,119 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000007_0
2024-11-18 08:59:05,119 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:05,120 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:05,120 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:05,120 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/kms-site.xml:0+682
2024-11-18 08:59:05,155 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:05,156 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:05,156 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:05,156 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:05,156 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:05,156 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:05,160 INFO mapred.LocalJobRunner:
2024-11-18 08:59:05,160 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:05,160 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:05,160 INFO mapred.MapTask: bufstart = 0; bufend = 1035; bufvoid = 104857600
2024-11-18 08:59:05,160 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214024(104856096); length = 373/6553600
2024-11-18 08:59:05,162 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:05,163 INFO mapred.Task: Task:attempt_local850210037_0001_m_000007_0 is done. And is in the process of committing
2024-11-18 08:59:05,165 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:05,165 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000007_0' done.
2024-11-18 08:59:05,165 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000007_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=324245
                FILE: Number of bytes written=861261
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=27969
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=19
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=20
                Map output records=94
                Map output bytes=1035
                Map output materialized bytes=1015
                Input split bytes=120
                Combine input records=94
                Combine output records=75
                Spilled Records=75
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=1024983040
        File Input Format Counters
                Bytes Read=682
2024-11-18 08:59:05,165 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000007_0
2024-11-18 08:59:05,165 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_m_000008_0
2024-11-18 08:59:05,166 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:05,166 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:05,166 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:05,167 INFO mapred.MapTask: Processing split: hdfs://4df3c0c3d6e6:8020/user/hadoop/input/httpfs-site.xml:0+620
2024-11-18 08:59:05,205 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-11-18 08:59:05,205 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-11-18 08:59:05,205 INFO mapred.MapTask: soft limit at 83886080
2024-11-18 08:59:05,205 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-11-18 08:59:05,205 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-11-18 08:59:05,206 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-11-18 08:59:05,210 INFO mapred.LocalJobRunner:
2024-11-18 08:59:05,210 INFO mapred.MapTask: Starting flush of map output
2024-11-18 08:59:05,210 INFO mapred.MapTask: Spilling map output
2024-11-18 08:59:05,210 INFO mapred.MapTask: bufstart = 0; bufend = 939; bufvoid = 104857600
2024-11-18 08:59:05,210 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214060(104856240); length = 337/6553600
2024-11-18 08:59:05,211 INFO mapred.MapTask: Finished spill 0
2024-11-18 08:59:05,212 INFO mapred.Task: Task:attempt_local850210037_0001_m_000008_0 is done. And is in the process of committing
2024-11-18 08:59:05,214 INFO mapred.LocalJobRunner: map
2024-11-18 08:59:05,214 INFO mapred.Task: Task 'attempt_local850210037_0001_m_000008_0' done.
2024-11-18 08:59:05,214 INFO mapred.Task: Final Counters for attempt_local850210037_0001_m_000008_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=324864
                FILE: Number of bytes written=862235
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=28589
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=21
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=17
                Map output records=85
                Map output bytes=939
                Map output materialized bytes=942
                Input split bytes=123
                Combine input records=85
                Combine output records=70
                Spilled Records=70
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=1130364928
        File Input Format Counters
                Bytes Read=620
2024-11-18 08:59:05,214 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_m_000008_0
2024-11-18 08:59:05,215 INFO mapred.LocalJobRunner: map task executor complete.
2024-11-18 08:59:05,217 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2024-11-18 08:59:05,218 INFO mapred.LocalJobRunner: Starting task: attempt_local850210037_0001_r_000000_0
2024-11-18 08:59:05,224 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-11-18 08:59:05,224 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false 
2024-11-18 08:59:05,225 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-11-18 08:59:05,227 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7059d9fd
2024-11-18 08:59:05,227 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-11-18 08:59:05,249 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=1264687488, maxSingleShuffleLimit=316171872, mergeThreshold=834693760, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-11-18 08:59:05,251 INFO reduce.EventFetcher: attempt_local850210037_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-11-18 08:59:05,263 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000002_0 decomp: 2376 len: 2380 to MEMORY
2024-11-18 08:59:05,265 INFO reduce.InMemoryMapOutput: Read 2376 bytes from map-output for attempt_local850210037_0001_m_000002_0
2024-11-18 08:59:05,266 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2376, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2376 
2024-11-18 08:59:05,267 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000005_0 decomp: 1214 len: 1218 to MEMORY   
2024-11-18 08:59:05,267 INFO reduce.InMemoryMapOutput: Read 1214 bytes from map-output for attempt_local850210037_0001_m_000005_0
2024-11-18 08:59:05,267 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1214, inMemoryMapOutputs.size() -> 2, commitMemory -> 2376, usedMemory ->3590
2024-11-18 08:59:05,268 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000006_0 decomp: 1188 len: 1192 to MEMORY   
2024-11-18 08:59:05,268 INFO reduce.InMemoryMapOutput: Read 1188 bytes from map-output for attempt_local850210037_0001_m_000006_0
2024-11-18 08:59:05,268 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1188, inMemoryMapOutputs.size() -> 3, commitMemory -> 3590, usedMemory ->4778
2024-11-18 08:59:05,269 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
        at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
        at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:271)
        at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:148)
        at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:209)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
2024-11-18 08:59:05,270 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000000_0 decomp: 5166 len: 5170 to MEMORY   
2024-11-18 08:59:05,271 INFO reduce.InMemoryMapOutput: Read 5166 bytes from map-output for attempt_local850210037_0001_m_000000_0
2024-11-18 08:59:05,271 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5166, inMemoryMapOutputs.size() -> 4, commitMemory -> 4778, usedMemory ->9944
2024-11-18 08:59:05,272 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000003_0 decomp: 1774 len: 1778 to MEMORY   
2024-11-18 08:59:05,272 INFO reduce.InMemoryMapOutput: Read 1774 bytes from map-output for attempt_local850210037_0001_m_000003_0
2024-11-18 08:59:05,272 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1774, inMemoryMapOutputs.size() -> 5, commitMemory -> 9944, usedMemory ->11718
2024-11-18 08:59:05,272 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000004_0 decomp: 1295 len: 1299 to MEMORY   
2024-11-18 08:59:05,273 INFO reduce.InMemoryMapOutput: Read 1295 bytes from map-output for attempt_local850210037_0001_m_000004_0
2024-11-18 08:59:05,273 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1295, inMemoryMapOutputs.size() -> 6, commitMemory -> 11718, usedMemory ->13013
2024-11-18 08:59:05,273 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000007_0 decomp: 1011 len: 1015 to MEMORY   
2024-11-18 08:59:05,273 INFO reduce.InMemoryMapOutput: Read 1011 bytes from map-output for attempt_local850210037_0001_m_000007_0
2024-11-18 08:59:05,273 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1011, inMemoryMapOutputs.size() -> 7, commitMemory -> 13013, usedMemory ->14024
2024-11-18 08:59:05,274 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000001_0 decomp: 6329 len: 6333 to MEMORY   
2024-11-18 08:59:05,274 INFO reduce.InMemoryMapOutput: Read 6329 bytes from map-output for attempt_local850210037_0001_m_000001_0
2024-11-18 08:59:05,275 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6329, inMemoryMapOutputs.size() -> 8, commitMemory -> 14024, usedMemory ->20353
2024-11-18 08:59:05,275 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local850210037_0001_m_000008_0 decomp: 938 len: 942 to MEMORY     
2024-11-18 08:59:05,275 INFO reduce.InMemoryMapOutput: Read 938 bytes from map-output for attempt_local850210037_0001_m_000008_0
2024-11-18 08:59:05,275 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 938, inMemoryMapOutputs.size() -> 9, commitMemory -> 20353, usedMemory ->21291
2024-11-18 08:59:05,276 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-11-18 08:59:05,276 INFO mapred.LocalJobRunner: 9 / 9 copied.
2024-11-18 08:59:05,276 INFO reduce.MergeManagerImpl: finalMerge called with 9 in-memory map-outputs and 0 on-disk map-outputs
2024-11-18 08:59:05,281 INFO mapred.Merger: Merging 9 sorted segments
2024-11-18 08:59:05,281 INFO mapred.Merger: Down to the last merge-pass, with 9 segments left of total size: 21237 bytes
2024-11-18 08:59:05,285 INFO reduce.MergeManagerImpl: Merged 9 segments, 21291 bytes to disk to satisfy reduce memory limit
2024-11-18 08:59:05,285 INFO reduce.MergeManagerImpl: Merging 1 files, 21279 bytes from disk
2024-11-18 08:59:05,286 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-11-18 08:59:05,286 INFO mapred.Merger: Merging 1 sorted segments
2024-11-18 08:59:05,286 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21269 bytes
2024-11-18 08:59:05,286 INFO mapred.LocalJobRunner: 9 / 9 copied.
2024-11-18 08:59:05,300 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2024-11-18 08:59:05,314 INFO hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.17.0.2:9866 for /user/hadoop/output/_temporary/0/_temporary/attempt_local850210037_0001_r_000000_0/part-r-00000
2024-11-18 08:59:05,317 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-11-18 08:59:05,329 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/output/_temporary/0/_temporary/attempt_local850210037_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-1695392030_1
2024-11-18 08:59:05,332 INFO mapred.Task: Task:attempt_local850210037_0001_r_000000_0 is done. And is in the process of committing
2024-11-18 08:59:05,334 INFO mapred.LocalJobRunner: 9 / 9 copied.
2024-11-18 08:59:05,334 INFO mapred.Task: Task attempt_local850210037_0001_r_000000_0 is allowed to commit now
2024-11-18 08:59:05,340 INFO output.FileOutputCommitter: Saved output of task 'attempt_local850210037_0001_r_000000_0' to hdfs://4df3c0c3d6e6:8020/user/hadoop/output     
2024-11-18 08:59:05,340 INFO mapred.LocalJobRunner: reduce > reduce
2024-11-18 08:59:05,340 INFO mapred.Task: Task 'attempt_local850210037_0001_r_000000_0' done.
2024-11-18 08:59:05,341 INFO mapred.Task: Final Counters for attempt_local850210037_0001_r_000000_0: Counters: 30
        File System Counters
                FILE: Number of bytes read=367758
                FILE: Number of bytes written=883514
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=28589
                HDFS: Number of bytes written=10327
                HDFS: Number of read operations=26
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=3
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=588
                Reduce shuffle bytes=21327
                Reduce input records=1223
                Reduce output records=588
                Spilled Records=1223
                Shuffled Maps =9
                Failed Shuffles=0
                Merged Map outputs=9
                GC time elapsed (ms)=11
                Total committed heap usage (bytes)=1220542464
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=10327
2024-11-18 08:59:05,341 INFO mapred.LocalJobRunner: Finishing task: attempt_local850210037_0001_r_000000_0
2024-11-18 08:59:05,341 INFO mapred.LocalJobRunner: reduce task executor complete.
2024-11-18 08:59:05,357 INFO hdfs.StateChange: DIR* completeFile: /user/hadoop/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1695392030_1
2024-11-18 08:59:05,568 INFO mapreduce.Job: Job job_local850210037_0001 running in uber mode : false
2024-11-18 08:59:05,569 INFO mapreduce.Job:  map 100% reduce 100%
2024-11-18 08:59:05,569 INFO mapreduce.Job: Job job_local850210037_0001 completed successfully
2024-11-18 08:59:05,576 INFO mapreduce.Job: Counters: 36
        File System Counters
                FILE: Number of bytes read=3264130
                FILE: Number of bytes written=8592971
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=243235
                HDFS: Number of bytes written=10327
                HDFS: Number of read operations=143
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=12
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=751
                Map output records=3063
                Map output bytes=38519
                Map output materialized bytes=21327
                Input split bytes=1104
                Combine input records=3063
                Combine output records=1223
                Reduce input groups=588
                Reduce shuffle bytes=21327
                Reduce input records=1223
                Reduce output records=588
                Spilled Records=2446
                Shuffled Maps =9
                Failed Shuffles=0
                Merged Map outputs=9
                GC time elapsed (ms)=11
                Total committed heap usage (bytes)=7600078848
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=28589
        File Output Format Counters
                Bytes Written=10327
root@4df3c0c3d6e6:/# hdfs dfs -cat /user/hadoop/output/part-r-00000
2024-11-18 08:59:22,260 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
"*"21
"AS     9
"License");     9
"alice,bob      21
"clumping"      1
(ASF)   1
(root   1
(the    9
-->     18
-1      1
-1,     1
0.0     1
1-MAX_INT.      1
1.      1
1.0.    1
2.0     9
40      2
40+20=60        1
:       2
<!--    18
</configuration>        9
</description>  33
</name> 2
</property>     57
<?xml   8
<?xml-stylesheet        4
<configuration> 9
<description>   31
<description>ACL        25
<description>Default    1
<name>default.key.acl.DECRYPT_EEK</name>        1
<name>default.key.acl.GENERATE_EEK</name>       1
<name>default.key.acl.MANAGEMENT</name> 1
<name>default.key.acl.READ</name>       1
<name>hadoop.kms.acl.CREATE</name>      1
<name>hadoop.kms.acl.DECRYPT_EEK</name> 1
<name>hadoop.kms.acl.DELETE</name>      1
<name>hadoop.kms.acl.GENERATE_EEK</name>        1
<name>hadoop.kms.acl.GET</name> 1
<name>hadoop.kms.acl.GET_KEYS</name>    1
<name>hadoop.kms.acl.GET_METADATA</name>        1
<name>hadoop.kms.acl.ROLLOVER</name>    1
<name>hadoop.kms.acl.SET_KEY_MATERIAL</name>    1
<name>security.admin.operations.protocol.acl</name>     1
<name>security.applicationclient.protocol.acl</name>    1
<name>security.applicationhistory.protocol.acl</name>   1
<name>security.applicationmaster-nodemanager.applicationmaster.protocol.acl</name>      1
<name>security.applicationmaster.protocol.acl</name>    1
<name>security.client.datanode.protocol.acl</name>      1
<name>security.client.protocol.acl</name>       1
<name>security.collector-nodemanager.protocol.acl</name>        1
<name>security.containermanagement.protocol.acl</name>  1
<name>security.datanode.protocol.acl</name>     1
<name>security.distributedscheduling.protocol.acl</name>        1
<name>security.ha.service.protocol.acl</name>   1
<name>security.inter.datanode.protocol.acl</name>       1
<name>security.interqjournal.service.protocol.acl</name>        1
<name>security.job.client.protocol.acl</name>   1
<name>security.job.task.protocol.acl</name>     1
<name>security.mrhs.client.protocol.acl</name>  1
<name>security.namenode.protocol.acl</name>     1
<name>security.qjournal.service.protocol.acl</name>     1
<name>security.refresh.policy.protocol.acl</name>       1
<name>security.refresh.user.mappings.protocol.acl</name>        1
<name>security.resourcelocalizer.protocol.acl</name>    1
<name>security.resourcemanager-administration.protocol.acl</name>       1
<name>security.resourcetracker.protocol.acl</name>      1
<name>security.zkfc.protocol.acl</name> 1
<name>yarn.scheduler.capacity.application.fail-fast</name>      1
<name>yarn.scheduler.capacity.maximum-am-resource-percent</name>        1
<name>yarn.scheduler.capacity.maximum-applications</name>       1
<name>yarn.scheduler.capacity.node-locality-delay</name>        1
<name>yarn.scheduler.capacity.per-node-heartbeat.maximum-offswitch-assignments</name>   1
<name>yarn.scheduler.capacity.queue-mappings-override.enable</name>     1
<name>yarn.scheduler.capacity.queue-mappings</name>     1
<name>yarn.scheduler.capacity.rack-locality-additional-delay</name>     1
<name>yarn.scheduler.capacity.resource-calculator</name>        1
<name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>  1
<name>yarn.scheduler.capacity.root.default.acl_application_max_priority</name>  1
<name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>       1
<name>yarn.scheduler.capacity.root.default.capacity</name>      1
<name>yarn.scheduler.capacity.root.default.default-application-lifetime 1
<name>yarn.scheduler.capacity.root.default.maximum-application-lifetime 1
<name>yarn.scheduler.capacity.root.default.maximum-capacity</name>      1
<name>yarn.scheduler.capacity.root.default.state</name> 1
<name>yarn.scheduler.capacity.root.default.user-limit-factor</name>     1
<name>yarn.scheduler.capacity.root.queues</name>        1
<property>      57
<property><name>dfs.client.use.datanode.hostname</name><value>true</value></property>   1
<property><name>dfs.datanode.use.datanode.hostname</name><value>true</value></property> 1
<property><name>dfs.namenode.http-bind-host</name><value>0.0.0.0</value></property>     1
<property><name>dfs.namenode.https-bind-host</name><value>0.0.0.0</value></property>    1
<property><name>dfs.namenode.name.dir</name><value>file:///hadoop/dfs/name</value></property>   1
<property><name>dfs.namenode.rpc-bind-host</name><value>0.0.0.0</value></property>      1
<property><name>dfs.namenode.servicerpc-bind-host</name><value>0.0.0.0</value></property>       1
<property><name>fs.defaultFS</name><value>hdfs://4df3c0c3d6e6:8020</value></property>   1
<property><name>yarn.nodemanager.bind-host</name><value>0.0.0.0</value></property>      3
<property><name>yarn.resourcemanager.bind-host</name><value>0.0.0.0</value></property>  1
<property><name>yarn.timeline-service.bind-host</name><value>0.0.0.0</value></property> 1
<value>*</value>        41
<value>-1</value>       3
<value>0.1</value>      1
<value>10000</value>    1
<value>100</value>      2
<value>1</value>        2
<value>40</value>       1
<value></value> 1
<value>RUNNING</value>  1
<value>default</value>  1
<value>false</value>    2
<value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>   1
A       22
ACL     37
ACL,    2
ACLs    1
ANY     9
ASF     1
AdminOperationsProtocol.        1
Any     2
Apache  10
ApplicationClientProtocol,      1
ApplicationHistoryProtocol,     1
ApplicationMaster       1
ApplicationMasterProtocol,      2
ApplicationMasters      3
BASIS,  9
But     1
CONDITIONS      9
CPU     1
CREATE  1
CapacityScheduler       2
ClientDatanodeProtocol, 1
ClientProtocol, 1
CollectorNodemanagerProtocol,   1
Complementary   1
Configuring     1
ContainerManagementProtocol     1
Controller      1
Controls        1
CryptoExtension 2
DECRYPT_EEK     1
DatanodeProtocol,       1
Default 3
DefaultResourceCalculator       1
DistributedFileSystem.  1
DistributedSchedulingAMProtocol,        1
DominantResourceCalculator      1
Example:        1
Failover        1
For     22
Foundation      1
GENERATE_EEK    1
GET     2
HAAdmin 1
HAService       1
HSClientProtocol,       1
History 1
IS"     9
If      5
In      1
Increasing      1
InterDatanodeProtocol,  1
InterQJournalProtocol,  1
It      2
JN      2
JNs     1
KIND,   9
KMS     1
LICENSE 5
Legal   1
License 27
License,        9
License.        18
Licensed        9
Lower   1
MANAGEMENT      1
MR      2
MRClientProtocol,       1
Maximum 3
Memory  1
Memory, 1
NN      1
NOTICE  1
NamenodeProtocol,       1
NodeManager     3
Nodemanager     2
Note    2
Note,   1
Number  2
OF      9
OFF_SWITCH      2
OR      9
Protocols       1
Put     5
QJournalProtocol,       1
QuorumJournalManager    1
READ    1
RM      1
ROLLOVER        1
RUNNING 1
RefreshAuthorizationPolicyProtocol,     1
RefreshUserMappingsProtocol.    1
ResourceCalculator      1
ResourceLocalizer       2
ResourceManager 3
ResourceManagerAdministrationProtocol,  1
ResourceTrackerProtocol,        1
Resourcemanager 1
Resources       1
STOPPED.        1
See     15
Server  1
Site    1
Software        1
State   1
TaskUmbilicalProtocol,  1
The     54
This    6
Typically       1
Unless  9
Used    2
User    1
Version 9
WARRANTIES      9
WITHOUT 9
We      2
When    2
Whether 1
YARN    2
You     9
ZK      1
[user={name}    1
[u|g]:[name]:[queue_name][,next 1
a       58
access  1
accompanying    5
account.        2
acls    4
active  1
additional      2
admin   2
administer      1
administrators  1
after   5
agreed  9
agreements.     1
all     27
allow   1
allowed 1
allowed.</description>  21
also    1
an      11
and     70
any     1
applicable      11
application     8
applications    5
applications'   1
applications.   1
approximately   1
are     27
as      10
assign  1
assigning       1
assignments     3
at      10
attempt 1
attempts        2
based   1
basis   1
be      16
blank.  21
block   1
by      52
calculated      1
can     9
can't   1
capacity        1
capacity.</description> 1
case,   1
changes 1
client  2
client-to-datanode      1
clients 3
cluster 3
cluster.        1
code    1
collector       1
comma-separated 21
commands        1
commands.       2
communciate     2
communicate     12
communicate.    2
compare 2
compliance      9
concurrent      1
config  1
configuration   1
configuration.  2
configured      3
considered      2
constraint      1
container       1
containers      2
containers,     1
containers.     2
context.        1
contributor     1
controls        1
copy    9
copyright       1
create-key      1
creating        1
datanodes       1
decryptEncryptedKey     1
default 13
default_priority={priority}]    1
defined.        4
delay   1
delete-key      1
dfsadmin        1
different       1
disabled.       2
disables        2
distributed     19
dominant-resource       1
during  2
e.g,    1
e.g.    21
each    7
edit    1
either  9
enabled,        1
encoding="UTF-8"?>      5
equal   2
etc.    3
example,        1
exceed  1
exceeds 2
except  9
explicitly      4
express 9
fail    1
false.  1
feature 2
feature.        1
file    12
file.   10
for     65
from    1
generateEncryptedKey    1
generation      1
generic 1
get-current-key 1
get-key-metadata        1
get-key-version 1
get-keys        1
get-keys-metadata       1
governing       9
group   42
group={name}    1
hard    1
has     1
heartbeat.      1
history 1
hot-reloaded    1
href="configuration.xsl"?>      4
http://www.apache.org/licenses/LICENSE-2.0      9
i.e.    2
if      4
ignored,        1
implementation  1
implied.        9
improve 1
in      36
in-effect.      1
information     1
instead 1
inter-datanode  1
into    2
is      76
it      3
job     4
jobs    4
key     7
key.    1
killed  1
killing 1
language        9
law     9
leaf    2
less    2
level   1
license 1
licenses        1
lifetime        6
lifetime.       3
limit   2
limitations     9
list    45
locality        1
locations       1
logs.</description>     1
longer  1
low     1
manage  1
map     2
mapping 1
mapping]*       1
mappings        1
mappings.       1
maps    1
masters 1
material        3
max_priority={priority} 1
maximum 3
may     18
means   21
missed  5
more    1
mradmin 1
multi-dimensional       1
name    1
namenode        1
namenode.       2
namenode.</description> 1
names.  21
no      1
node's  1
node-locality-delay     1
node-locality-delay=40  1
nodemanager     2
nodes   1
nodes.  1
not     18
number  6
obtain  9
of      77
off-switch      3
on      12
one     4
ones,   1
ones.   1
only    3
operations      5
operations.     8
opportunities   3
opportunities,  1
opportunities.  1
or      23
other   1
other.  7
over    1
overridden      1
override        1
overrides       5
ownership.      1
parameter,      2
parent  1
part    2
particular      1
pending 1
per     1
percent 1
percentage      1
permissions     9
place   1
point-in-time   2
policy  1
positive        1
present,        1
previous        1
priority.       1
properties      1
property        5
protocol        4
protocol,       2
provide 1
query   1
queue   8
queue). 1
queue.  7
queues  4
queues, 1
rack-local      3
rack-locality-delay=20, 1
rack.   1
rate    1
recovery        1
recovery.       1
reduce  2
refresh 2
refreshable.    1
regarding       1
request 1
request,        1
required        9
resource        1
resources       2
response.       2
result  1
returned        2
rolling 1
rollover-key    1
root    1
run     1
running 1
running.        1
same    1
schedule        2
scheduler       1
scheduler.      1
scheduling      3
scheduling.     1
secondary       1
seconds.        2
security        1
separated       21
server  1
service 2
setting 2
should  3
site-specific   5
size    3
software        9
sooner. 1
special 21
specific        10
specified       3
specify 1
stand-by        1
state   1
states  1
status  2
submission      2
submit  2
submitted       4
such    1
syntax  1
taken   2
taken.  1
target  1
tasks   1
tasktracker.    1
than    3
that    7
the     139
then    2
this    28
time    1
timeline        3
timestamp.      1
to      53
too     1
type="text/xsl" 4
u:%user:%user   1
under   28
unique  1
updating        1
use     11
used    24
user    48
user.   2
user?   1
users   24
users,wheel".   21
uses    2
using   1
v2      1
valid.  1
value   30
value,  2
values  2
version="1.0"   5
version="1.0"?> 3
via     1
well    1
when    3
which   10
while   1
who     3
will    12
with    28
work    1
writing,        9
you     10
zero    2

